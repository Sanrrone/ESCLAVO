rownames(taxid) <- getSequences(seqtab.nochim)
taxa<-taxid
taxa
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, 'D'), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, 'D'), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf <- 'Early'
samdf[samdf>100] <- 'Late'
rownames(samdf) <- samples.out
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
sample_data(samdf),
tax_table(taxa))
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),tax_table(taxa))
ps <- prune_samples(sample_names(ps) != 'Mock', ps) # Remove mock sample
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Sample') + theme_minimal()
ps.top20
otu_table(ps)
tax_table(ps)
head(tax_table(ps))
plot_bar(ps.top20, x='Sample', fill='genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
View(ps.top20)
ps.top20@otu_table
ps.top20@tax_table@.Data
head(ps.top20@tax_table@.Data)
plot_bar(ps.top20, x='Sample') + theme_minimal()
colnames(tax_table(ps.top20))
plot_bar(ps.top20, x='Sample', fill='genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill=genus) + theme_minimal()
plot_bar(ps.top20, x=Sample, fill=genus) + theme_minimal()
plot_bar(ps.top20, x=Sample, fill=domain) + theme_minimal()
colnames(otu_table(ps.top20))
rownames(otu_table(ps.top20))
rownames(tax_table(ps.top20))
colnames(otu_table(ps.top20))
colnames(tax_table(ps.top20))
tax_table(ps.top20)["phylum"]
tax_table(ps.top20)[,"phylum"]
plot_bar(ps.top20, x=Sample) + theme_minimal()
plot_bar(ps.top20, x='Sample') + theme_minimal()
taxa <- assignTaxonomy(seqtab.nochim, "~/Descargas/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
taxa
taxa <- assignTaxonomy(seqtab.nochim, "~/Descargas/silva_nr_v132_train_set.fa.gz", multithread=TRUE,verbose = T)
taxa <- addSpecies(taxa, "~/Descargas/silva_species_assignment_v128.fa.gz")
taxa
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),tax_table(taxa))
ps <- prune_samples(sample_names(ps) != 'Mock', ps) # Remove mock sample
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x='Sample') + theme_minimal()
dev.off()
plot_bar(ps.top20, x='Sample') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill="Genus") + theme_minimal()
taxa <- assignTaxonomy(seqtab.nochim, "~/Descargas/silva_nr_v132_train_set.fa", multithread=TRUE, verbose = T)
View(seqtab.nochim)
taxa <- addSpecies(taxa, "~/Descargas/silva_species_assignment_v128.fa")
class(taxa)
source('~/Programas/ESCLAVO/projects/2-taxInsight/dada2_assign.R', echo=TRUE)
dim(taxa)
rm(list=ls())
library(dada2)
path<-'/home/sandro/Programas/ESCLAVO/0-fastq16s'
fqpattern<-'.fastq.gz'
tolerance<-0.1
readlength<-153
projectfolder<-'/home/sandro/Programas/ESCLAVO/projects'
fnFs <- sort(list.files(path, pattern=paste0('1',fqpattern), full.names = TRUE))
fnRs <- sort(list.files(path, pattern=paste0('2',fqpattern), full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), '_'), `[`, 1)
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_F_filt',fqpattern))
filtRs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_R_filt',fqpattern))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
readtolerance<-readlength*tolerance
maxeeformula<- (0.01*readlength)+(0.012589254*readtolerance)
print(paste0('Doing filtering at maxEE ',maxeeformula))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=(readlength-readlength*tolerance),
maxN=0, maxEE=maxeeformula, truncQ=2, rm.phix=TRUE, minLen = 80,
compress=TRUE, multithread=TRUE)
print('Done')
write.table(out,'qc_filt.tsv',sep='\t')
print('learning from errors')
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
print('Done')
write.table(errF,'dada2_filt_errF.tsv',sep='\t')
write.table(errR,'dada2_filt_errR.tsv',sep='\t')
print('Dereplication')
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
print('Done')
print('Inferring sample composition')
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
print('Finally merge reads')
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
seqtab <- makeSequenceTable(mergers)
print('Done')
#seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(250,256)]) # to select specific seq length
seqtab.nochim <- removeBimeraDenovo(seqtab, method='consensus', multithread=TRUE, verbose=TRUE)
print(paste0('sequences kept after removing chimera step: ',sum(seqtab.nochim)/sum(seqtab)))
#make summary table
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c('input', 'filtered', 'denoisedF', 'denoisedR', 'merged', 'nonchim')
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
sapply(dadaFs, getN)
sapply(dadaRs, getN)
dadaFs
getN
sapply(dadaFs, getN)
dadaFs
getN
sapply(mergers, getN)
mergers
sapply(mergers, getN)
rm(list=ls())
library(dada2)
path<-'/home/sandro/Programas/ESCLAVO/0-fastq16s'
fqpattern<-'.fastq.gz'
tolerance<-0.1
readlength<-153
projectfolder<-'/home/sandro/Programas/ESCLAVO/projects'
fnFs <- sort(list.files(path, pattern=paste0('1',fqpattern), full.names = TRUE))
fnRs <- sort(list.files(path, pattern=paste0('2',fqpattern), full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), '_'), `[`, 1)
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_F_filt',fqpattern))
filtRs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_R_filt',fqpattern))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
readtolerance<-readlength*tolerance
maxeeformula<- (0.01*readlength)+(0.012589254*readtolerance)
print(paste0('Doing filtering at maxEE ',maxeeformula))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=(readlength-readlength*tolerance),
maxN=0, maxEE=maxeeformula, truncQ=2, rm.phix=TRUE, minLen = 80,
compress=TRUE, multithread=TRUE)
print('Done')
write.table(out,'qc_filt.tsv',sep='\t')
print('learning from errors')
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
print('Done')
write.table(errF,'dada2_filt_errF.tsv',sep='\t')
write.table(errR,'dada2_filt_errR.tsv',sep='\t')
print('Dereplication')
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
print('Done')
print('Inferring sample composition')
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
print('done')
print('Finally merge reads')
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
seqtab <- makeSequenceTable(mergers)
print('Done')
#seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(250,256)]) # to select specific seq length
seqtab.nochim <- removeBimeraDenovo(seqtab, method='consensus', multithread=TRUE, verbose=TRUE)
print(paste0('sequences kept after removing chimera step: ',sum(seqtab.nochim)/sum(seqtab)))
#make summary table
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
sapply(dadaFs, getN)
View(dadaFs)
sapply(list(dadaFs), getN)
if(is.list(dadaFs))
{}
is.list(dadaFs)
dadaFs
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
dadaFs<-list(dadaFs)
dadaFs
dadaRs<-list(dadaRs)
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
sapply(dadaFs, getN)
sapply(dadaRs, getN)
sapply(mergers, getN)
mergers<-list(mergers)
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c('input', 'filtered', 'denoisedF', 'denoisedR', 'merged', 'nonchim')
rownames(track) <- sample.names
write.table(track,'qc_summary.tsv', sep='\t')
track
path<-'/home/sandro/Programas/ESCLAVO/0-fastq16s'
fqpattern<-'.fastq.gz'
tolerance<-0.1
readlength<-153
projectfolder<-'/home/sandro/Programas/ESCLAVO/projects'
fnFs <- sort(list.files(path, pattern=paste0('1',fqpattern), full.names = TRUE))
fnRs <- sort(list.files(path, pattern=paste0('2',fqpattern), full.names = TRUE))
fnFs
sample.names <- sapply(strsplit(basename(fnFs), '_'), `[`, 1)
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_F_filt',fqpattern))
filtRs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_R_filt',fqpattern))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
readtolerance<-readlength*tolerance
maxeeformula<- (0.01*readlength)+(0.012589254*readtolerance)
print(paste0('Doing filtering at maxEE ',maxeeformula))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=(readlength-readlength*tolerance),
maxN=0, maxEE=maxeeformula, truncQ=2, rm.phix=TRUE, minLen = 80,
compress=TRUE, multithread=TRUE)
print('Done')
write.table(out,'qc_filt.tsv',sep='\t')
print('learning from errors')
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
print('Done')
write.table(errF,'dada2_filt_errF.tsv',sep='\t')
write.table(errR,'dada2_filt_errR.tsv',sep='\t')
print('Dereplication')
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
print('Done')
print('Inferring sample composition')
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
print('done')
print('Finally merge reads')
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
seqtab <- makeSequenceTable(mergers)
print('Done')
#seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(250,256)]) # to select specific seq length
seqtab.nochim <- removeBimeraDenovo(seqtab, method='consensus', multithread=TRUE, verbose=TRUE)
print(paste0('sequences kept after removing chimera step: ',sum(seqtab.nochim)/sum(seqtab)))
#make summary table
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
dadaFs
list(dadaFs)
length(dadaFs)
path<-'/home/sandro/Programas/ESCLAVO/0-fastq16s'
fqpattern<-'.fastq.gz'
tolerance<-0.1
readlength<-153
projectfolder<-'/home/sandro/Programas/ESCLAVO/projects'
fnFs <- sort(list.files(path, pattern=paste0('1',fqpattern), full.names = TRUE))
fnRs <- sort(list.files(path, pattern=paste0('2',fqpattern), full.names = TRUE))
fnFs
fnRs
sample.names <- sapply(strsplit(basename(fnFs), '_'), `[`, 1)
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_F_filt',fqpattern))
filtRs <- file.path(projectfolder, '1-qc', paste0(sample.names, '_R_filt',fqpattern))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
readtolerance<-readlength*tolerance
maxeeformula<- (0.01*readlength)+(0.012589254*readtolerance)
print(paste0('Doing filtering at maxEE ',maxeeformula))
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=(readlength-readlength*tolerance),
maxN=0, maxEE=maxeeformula, truncQ=2, rm.phix=TRUE, minLen = 80,
compress=TRUE, multithread=TRUE)
print('Done')
write.table(out,'qc_filt.tsv',sep='\t')
print('learning from errors')
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
print('Done')
write.table(errF,'dada2_filt_errF.tsv',sep='\t')
write.table(errR,'dada2_filt_errR.tsv',sep='\t')
print('Dereplication')
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
print('Done')
print('Inferring sample composition')
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
print('done')
print('Finally merge reads')
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
seqtab <- makeSequenceTable(mergers)
print('Done')
#seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(250,256)]) # to select specific seq length
seqtab.nochim <- removeBimeraDenovo(seqtab, method='consensus', multithread=TRUE, verbose=TRUE)
print(paste0('sequences kept after removing chimera step: ',sum(seqtab.nochim)/sum(seqtab)))
#make summary table
getN <- function(x) sum(getUniques(x))
dadaFs
length(dadaFs)
mergers
length(mergers)
sample.names
fnFs
length(fnFs)
if(length(fnFs)==1){
dadaFs<-list(dadaFs)
dadaRs<-list(dadaRs)
mergers<-list(mergers)
}
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
track
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c('input', 'filtered', 'denoisedF', 'denoisedR', 'merged', 'nonchim')
rownames(track) <- sample.names
write.table(track,'qc_summary.tsv', sep='\t')
save(seqtab.nochim,file = 'seqtab.nochim.RData')
library(dada2)
library(DECIPHER)
library(phyloseq)
library(Biostrings)
load('/home/sandro/Programas/ESCLAVO/projects/1-qc/seqtab.nochim.RData')
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
taxa <- assignTaxonomy(seqtab.nochim, '/home/sandro/Descargas/silva_nr_v132_train_set.fa', multithread=TRUE, verbose = T)
taxa
taxa <- addSpecies(taxa, '/home/sandro/Descargas/silva_species_assignment_v132.fa')
print("Done")
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, 'D'), `[`, 1)
gender <- substr(subject,1,1)
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
sample_data(samdf),
tax_table(taxa))
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
tax_table(taxa))
ps <- prune_samples(sample_names(ps) != 'Mock', ps) # Remove mock sample
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
sample_names(ps)
pdf('sampleTaxComposition.pdf', width=wformula, height=hformula)
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
dev.off()
wformula=length(sample_names(ps))*2.5
hformula=10
pdf('sampleTaxComposition.pdf', width=wformula, height=hformula)
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
dev.off()
wformula=5 + length(sample_names(ps))*2.5
hformula=10
pdf('sampleTaxComposition.pdf', width=wformula, height=hformula)
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
dev.off()
wformula=4 + length(sample_names(ps))*2.5
hformula=10
tax_table(ps.top20)
otu_table(ps.top20)
tax_table(ps.top20)
library(dada2)
library(DECIPHER)
library(phyloseq)
library(Biostrings)
library(ggplot2)
load('/home/sandro/Programas/ESCLAVO/projects/1-qc/seqtab.nochim.RData')
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
print('Doing assigment')
taxa <- assignTaxonomy(seqtab.nochim, '/home/sandro/Descargas/silva_nr_v132_train_set.fa', multithread=TRUE, verbose = T)
taxa <- addSpecies(taxa, '/home/sandro/Descargas/silva_species_assignment_v132.fa')
print('Done')
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), tax_table(taxa))
ps <- prune_samples(sample_names(ps) != 'Mock', ps) # Remove mock sample
write.table(otu_table(ps),'otu_table.tsv',sep='\t')
write.table(tax_table(ps),'tax_table.tsv',sep='\t')
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
wformula=4 + length(sample_names(ps))*2.5
hformula=10
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Family') + theme_minimal()
prevelancedf = apply(X = otu_table(s16sV1V3),
MARGIN = 1,
FUN = function(x){sum(x > 0)})
prevelancedf = apply(X = otu_table(ps),
MARGIN = 1,
FUN = function(x){sum(x > 0)})
prevelancedf
prevelancedf = data.frame(Prevalence = prevelancedf,
TotalAbundance = taxa_sums(ps),
tax_table(ps))
prevelancedf
countsdf = data.frame(TotalAbundance = taxa_sums(ps),
tax_table(ps))
countsdf
prevelancedf = data.frame(Prevalence = prevelancedf,
TotalAbundance = taxa_sums(ps),
tax_table(ps))
prevelancedf
sample_names(ps)
prevelancedf = apply(X = otu_table(ps),
MARGIN = 1,
FUN = function(x){sum(x > 0)})
prevelancedf
prevelancedf = data.frame(Prevalence = prevelancedf,
TotalAbundance = taxa_sums(ps),
tax_table(ps))
prevelancedf
taxprevalence = apply(X = otu_table(ps),
MARGIN = 1,
FUN = function(x){sum(x > 0)})
prevelancedf = data.frame(Prevalence = taxprevalence,
TotalAbundance = taxa_sums(ps),
tax_table(ps),stringsAsFactors = F)
load('/home/sandro/Programas/ESCLAVO/projects/1-qc/seqtab.nochim.RData')
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
print('Doing assigment')
taxa <- assignTaxonomy(seqtab.nochim, '/home/sandro/Descargas/silva_nr_v132_train_set.fa', multithread=TRUE, verbose = T)
taxa <- addSpecies(taxa, '/home/sandro/Descargas/silva_species_assignment_v132.fa')
print('Done')
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), tax_table(taxa))
ps <- prune_samples(sample_names(ps) != 'Mock', ps) # Remove mock sample
write.table(otu_table(ps),'otu_table.tsv',sep='\t')
write.table(tax_table(ps),'tax_table.tsv',sep='\t')
taxprevalence = apply(X = otu_table(ps),
MARGIN = 1,
FUN = function(x){sum(x > 0)})
taxprevalence
abudancedf = data.frame(prevalence = taxprevalence,
abundance = taxa_sums(ps),
tax_table(ps),
stringsAsFactors = F)
transform_sample_counts(ps)
transform_sample_counts(ps, function(x){sum(x > 0)})
transform_sample_counts(ps, fun = function(x){sum(x > 0)})
taxprevalence = function(x){sum(x > 0)}
taxprevalence
taxprevalence <- function(x){sum(x > 0)}
transform_sample_counts(ps, fun = taxprevalence)
otu_table(ps)
abudancedf<-otu_table(ps)
otu_table(ps)
abudancedf<-t(otu_table(ps))
abudancedf
abudancedf<-as.data.frame(t(otu_table(ps)))
View(abudancedf)
View(as.data.frame(tax_table()))
View(as.data.frame(tax_table(ps)))
nrow(as.data.frame(tax_table(ps)))
nrow(abudancedf)
taxtable<-as.data.frame(tax_table(ps))
seqtab.nochim
taxa
abudancedf<-cbind(taxa,abudancedf[rownames(taxa),])
View(abudancedf)
1:nrow(abudancedf)
rownames(abudancedf)<-1:nrow(abudancedf)
View(abudancedf)
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus', dodge=1) + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus',stat="dodge") + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal() + geom_bar(position="fill")
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal() + geom_bar(position="fill", stat="fill")
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal() + geom_bar(position="fill", stat="dodge")
plot_bar(ps.top20, x='Sample', fill='Genus') + theme_minimal() + geom_bar(position="fill", stat="identity")
plot_bar(ps.top20, x='Sample', fill='Genus', position="fill") + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus') + geom_bar(position="fill", stat="identity") + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus') + geom_bar(position="fill", stat="identity")
plot_bar
plot_bar(ps.top20, x='Sample', fill='Genus',) + geom_bar(position="fill", stat="identity", color="black") + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus',) + geom_bar(position="fill", stat="identity", color=NULL) + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus',) + geom_bar(position="fill", stat="identity", color=NA) + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Family') + geom_bar(position="fill", stat="identity", color="black") + theme_minimal()
plot_bar(ps.top20, x='Sample', fill='Genus',) + geom_bar(position="fill", stat="identity", color="black") + theme_minimal()
abudancedf<-as.data.frame(t(seqtab.nochim))
abudancedf<-cbind(taxa,abudancedf[rownames(taxa),])
rownames(abudancedf)<-1:nrow(abudancedf)
write.table(abudancedf,'abundance.tsv',row.names = F,sep = '\t')
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), tax_table(taxa))
write.table(otu_table(ps),'otu_table.tsv',sep='\t')
write.table(tax_table(ps),'tax_table.tsv',sep='\t')
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
wformula=4 + length(sample_names(ps))*2.5
hformula=10
plot_bar(ps.top20, x='Sample', fill='Genus',) + geom_bar(position="fill", stat="identity", color="black") +
theme_minimal() + theme(axis.text.x = element_text(angle = 65, hjust = 1))
plot_bar(ps.top20, x='Sample', fill='Family') + geom_bar(position="fill", stat="identity", color="black") +
theme_minimal() + theme(axis.text.x = element_text(angle = 65, hjust = 1))
runApp()
reactivePoll(intervalMillis = 5000, session = session,
checkFunc = function(){digest(paste0(Ppath,"/",pname,"_eConf.tsv"),algo="md5",file=TRUE)},
valueFunc = function(){read.csv(paste0(Ppath,"/",pname,"_eConf.tsv"),
header = T,sep = "\t",stringsAsFactors = F,
row.names = 1)})
runApp()
system2(command = "bash",
args = paste0("pipelines/",analysis,"/",analysis,".sh --force -p ",pfolder," -f ",folder," -pt ",fqpattern),
wait = F,stdout = FALSE)
shiny::runApp()
runApp()
projectConf(reactivePoll(intervalMillis = 5000, session = session,
checkFunc = function(){digest(paste0(Ppath,"/",pname,"_eConf.tsv"),algo="md5",file=TRUE)},
valueFunc = function(){read.csv(paste0(Ppath,"/",pname,"_eConf.tsv"),
header = T,sep = "\t",stringsAsFactors = F,
row.names = )})())
runApp()
